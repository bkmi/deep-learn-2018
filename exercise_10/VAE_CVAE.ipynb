{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    def __init__(self, batch_size=32, latent_dim=2):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = tf.cast(tf.placeholder_with_default(batch_size, shape=()), dtype=tf.int64)\n",
    "        self.convd_size = 22\n",
    "        self.dense_size = int(np.sqrt(self.convd_size * self.convd_size * 16))\n",
    "        \n",
    "        self.is_training = tf.placeholder_with_default(True, shape=())\n",
    "        self.image_input = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1])\n",
    "        self.image_batch, self.iterator, _ = self._make_dataset_iterator()\n",
    "        self.z_mean, self.z_log_var = self._encoder()\n",
    "        self.z = self._sampler()\n",
    "        self.decoded = self._decoder()\n",
    "        \n",
    "        self.loss, self.optimization, self.reconstruction_loss, self.latent_loss = self._make_loss_opt()\n",
    "        \n",
    "    def _make_dataset_iterator(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(self.image_input)\n",
    "        dataset = dataset.shuffle(buffer_size=20000)\n",
    "        dataset = dataset.batch(batch_size=self.batch_size)\n",
    "\n",
    "        iterator = dataset.make_initializable_iterator()\n",
    "        image_batch = iterator.get_next()\n",
    "        return image_batch, iterator, dataset\n",
    "        \n",
    "    def _encoder(self):\n",
    "        conv_kwargs = {'kernel_size': 3, 'filters': 16, 'padding': 'valid', 'strides': 1, 'activation': tf.nn.relu}\n",
    "        x = tf.layers.conv2d(self.image_batch, **conv_kwargs)\n",
    "        x = tf.layers.batch_normalization(x, training=self.is_training)\n",
    "        x = tf.layers.conv2d(x, **conv_kwargs)\n",
    "        x = tf.layers.conv2d(x, **conv_kwargs)\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = tf.layers.dense(x, units=self.dense_size, activation=tf.nn.relu)\n",
    "        z_mean = tf.layers.dense(x, units=self.latent_dim)\n",
    "        z_log_var = tf.layers.dense(x, units=self.latent_dim)\n",
    "        return z_mean, z_log_var\n",
    "    \n",
    "    def _sampler(self):\n",
    "        self.samples = tf.random_normal(shape=[self.batch_size, self.latent_dim],\n",
    "                                   mean=0.,\n",
    "                                   stddev=1.,\n",
    "                                   dtype=tf.float32)\n",
    "        z = self.z_mean + tf.sqrt(tf.exp(self.z_log_var)) * self.samples\n",
    "        return z\n",
    "        \n",
    "    def _decoder(self):\n",
    "        conv_kwargs = {'kernel_size': 3, 'strides': 1, 'activation': tf.nn.relu}\n",
    "        self.z = tf.Print(self.z, [self.z_mean, self.z_log_var, self.samples])\n",
    "        x = tf.layers.dense(self.z, units=self.dense_size, activation=tf.nn.relu)\n",
    "        x = tf.layers.dense(x, units=self.dense_size ** 2, activation=tf.nn.relu)\n",
    "        x = tf.reshape(x, shape=[-1, self.convd_size, self.convd_size, 16])\n",
    "        x = tf.layers.conv2d_transpose(x, filters=16, padding='valid', **conv_kwargs)\n",
    "        x = tf.layers.conv2d_transpose(x, filters=16, padding='valid', **conv_kwargs)\n",
    "        decoded = tf.layers.conv2d_transpose(x, filters=1,padding='valid', **conv_kwargs)\n",
    "        return decoded\n",
    "    \n",
    "    def _make_loss_opt(self):        \n",
    "        reconstruction_loss = 0.5 * tf.reduce_sum(tf.squared_difference(self.decoded, self.image_batch), axis=[1,2,3])\n",
    "        reconstruction_loss = tf.reduce_mean(reconstruction_loss)\n",
    "        latent_loss = 0.5 * tf.reduce_sum(1 + self.z_log_var - self.z_mean ** 2 - tf.exp(self.z_log_var), axis=1)\n",
    "        latent_loss = tf.reduce_mean(latent_loss)\n",
    "        loss = reconstruction_loss + latent_loss\n",
    "        \n",
    "        opt = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "        return loss, opt, reconstruction_loss, latent_loss\n",
    "    \n",
    "    def train(self, session, images):\n",
    "        session.run(self.iterator.initializer, feed_dict={self.image_input: images})\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                _, loss, reconstruction_loss, latent_loss = session.run(\n",
    "                    [self.optimization, self.loss, self.reconstruction_loss, self.latent_loss], \n",
    "                    feed_dict={self.is_training: True}\n",
    "                )\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "                \n",
    "        return loss, reconstruction_loss, latent_loss\n",
    "    \n",
    "    def predict(self, session, images):\n",
    "        session.run(self.iterator.initializer, feed_dict={self.image_input: images})\n",
    "        \n",
    "        _, loss, reconstruction_loss, latent_loss = session.run(\n",
    "            [self.optimization, self.loss, self.reconstruction_loss, self.latent_loss], \n",
    "            feed_dict={self.batch_size: 1,\n",
    "                       self.is_training: True, \n",
    "                       self.image_input: images}\n",
    "        )\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('vae-cvae-challenge.npz') as fh:\n",
    "    images, labels = fh['data_x'], fh['data_y']\n",
    "    images = np.reshape(images, newshape=[-1, 28, 28, 1])\n",
    "print(f'image shape: {images.shape}, labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_epochs = 1\n",
    "vae = VAE()\n",
    "\n",
    "# Check sampling with tf.Print (alraedy in there, but logging doesn't work in jupyter.)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(count_epochs):\n",
    "        loss, reconstruction_loss, latent_loss = vae.train(sess, images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.constant(np.random.rand(10,20,5))\n",
    "x = tf.reshape(x, shape=tf.constant((-1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item = tf.constant(np.random.rand(10,5,3,2))\n",
    "ok = tf.reduce_sum(np.random.rand(10,5,3,2), axis=item.rank)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(ok.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate(predicate, images, iterator, session):\n",
    "    session.run(iterator.initializer, feed_dict={real_images: images})\n",
    "    while True:\n",
    "        try:\n",
    "            result = session.run(predicate)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
